---
layout: default
---

<!-- Page Content -->
<div class="container">

    <!-- Portfolio Item Row -->
    <div class="row">
        <div class="row">
            <div class="col-md-7">
                <h3>Welcome</h3>
            </div>
        </div>
        <div class="row">
            <div class="col-md-8">
                <p>I am an assistant professor of Computer Science at Wellesley College.</p>
                <h3>Research</h3>
                <p>My research focuses on the intersection of language, cognition, and computation.</p>

                <p>Within computer science, much of my work focuses on evaluating large language models for natural language and code generation. What are the abilities and limitations of LLMs? Can LLMs help non-expert programmers? I study these questions from a variety of angles, including model development, benchmarking and evaluation, and human-computer interaction studies.</p>

                <p>Within linguistics, I study how context-sensitive meaning is encoded in natural language. I build computational models to understand how conversation participants use knowledge about each other's mental states, and use psycholinguistic methods to understand how people select context-sensitive expressions.</p>

                 <!--<p>My dissertation, <b><a href="https://ling.auf.net/lingbuzz/005454?_s=6KVdJSTSZvacd4I_&_k=cqAtx-8HmlYak3QH">Shifting the Perspectival Landscape</a></b>, is now on <a href="https://ling.auf.net/lingbuzz/005454?_s=6KVdJSTSZvacd4I_&_k=cqAtx-8HmlYak3QH">LingBuzz</a>.</p>-->
            </div>
            <div class="col-md-1">
            </div>
            <div class="col-md-3">
                <a href="#">
                    <img class="img-responsive thumbnail" src="img/ta_small.jpg">
                </a>
                <div style="display: grid; justify-content:center">carolyn.anderson AT wellesley.edu</div>
                <div style="display: grid; justify-content:center"><h6></h6></div>
                <!--<div style="display: grid; justify-content:center">
                    <h3 class="interests">Interests</h3>
                    <h5 class="interests">o Computational Modeling</h5>
                    <h5 class="interests">o Semantics and Pragmatics</h5>
                    <h5 class="interests">o Machine Learning</h5>
                    <h5 class="interests">o Psycholinguistics</h5>
                </div>-->
            </div>
        </div>
        <div class="row">
            <div class="col-md-10">
                <h3>News</h3>
                <p>o I'm on junior research leave F24-S25</p>
                <p>o New preprint: <a href="https://arxiv.org/abs/2502.01584"><b>PhD Knowledge Not Required: A Reasoning Challenge for Large Language Models</b></a></p>
                <p>o January 2025: <b>Components of Character</b> accepted to the Journal of Data Mining and Digital Humanities.</p>
                <p>o January 2025: <b>But *How* Do They Use It? Scaffolding the Introduction of Generative AI Across the SLAC Curriculum</b> was accepted to Innovations and Opportunities in Liberal Arts Computing Education at SIGCSE 2025</p>
                <p>o January 2025: <b>Perspective Shift with Korean Motion Verbs</b> has been accepted to GLOW 47</p>
                <p>o January 2025: <a href="http://arxiv.org/abs/2410.19792"><b>Substance Beats Style</b></a> accepted to NAACL 2025</a>
                <p>o December 2024: <b>Anaphoric Relations and Quoting Out of Context</b> accepted to RED 2025 Conference</p>
                <p>o November 2024: <a href="https://arxiv.org/abs/2408.16131"><b>AustenAlike</b></a> presented at NLP4DH at EMNLP 2024</p>
                <p>o November 2024: I spoke on World of Wellesley's <a href="https://youtu.be/lSqVCP_Bhh8?feature=shared">panel discussion of Unmasking AI</a></p>
                <p>o October 2024: <a href="https://arxiv.org/abs/2308.09895"><b>MultiPL-T</b></a> presented at OOPSLA 2024</p>
                <p>o October 2024: <a href="https://arxiv.org/abs/2312.12450"><b>Can It Edit?</b></a> presented at COLM 2024</p>
                <p>o August 2024: <a href="https://arxiv.org/abs/2306.04556"><b>StudentEval</b></a> presented at ACL 2024</p>
                <p>o August 2024: Two papers presented at the TeachNLP workshop at ACL 2024</p> 
                <p>o New preprint: <a href="https://arxiv.org/abs/2408.05894"><b>GlyphPattern</b></a>, a benchmark for abstract pattern recognition in VLMs</p> 
                <!--  
                <p>o June 2024: <a href="https://dl.acm.org/doi/fullHtml/10.1145/3663384.3663393"><b>Non-Expert Programmers in the Generative AI Future</b></a> presented at CHIWORK 2024</p>
                <p>o June 2024: I co-presented Manuscript Connections at the Computer Vision and Art History Today convening</p>
                <p>o June 2024: <b>Parenthesized Modifiers in English and Korean: What They (May) Mean</b> presented at ELM 3</p>
                <p>o May 2024: <a href="https://dl.acm.org/doi/pdf/10.1145/3613904.3642706"><b>How Beginning Programmers and Code LLMs (Mis)read Each Other</b></a> presented at CHI 2024</p> 
                <p>o New preprint: <a href="http://arxiv.org/abs/2410.19792"><b>Substance Beats Style: Why Beginning Students Fail to Code with LLMs</b></a>
                <p>o May 2024: <b>What Parenthesized Modifiers (May) Mean</b> presented at HSP 2024</p>
                <p>o September 2024: <a href="https://arxiv.org/abs/2408.16131"><b>AustenAlike</b></a> accepted to NLP4DH at EMNLP 2024</p>
                <p>o July 2024: <a href="https://arxiv.org/abs/2312.12450"><b>Can It Edit?</b></a> accepted to COLM 2024</p>
                <p>o July 2024: <a href="https://arxiv.org/abs/2308.09895"><b>MultiPL-T</b></a> accepted to OOPSLA 2024</p>
                <p>o New preprint: <a href="https://arxiv.org/abs/2408.16131"><b>AustenAlike</b></a>, a benchmark for evaluating computational representations of literary characters</p>
                <p>o May 2024: EASEL lab member Anders Freeman successfully defends their honors thesis. Congrats!</p>
                <p>o February 2024: <b><a href="https://arxiv.org/abs/2402.19173">StarCoder 2</a></b> released</p>
                <p>o June 2024: Two papers accepted to the Teaching Materials track at TeachNLP 2024</p>  
                <p>o May 2024: <a href="https://arxiv.org/abs/2306.04556"><b>StudentEval</b></a> accepted to ACL Findings</p>
                <p>o April 2024: EASEL lab member Sydney Nguyen wins Best Presentation award for <a href="https://arxiv.org/abs/2306.04556"><b>StudentEval</b></a> at the LLM4Code workshop at ICSE 2024</p>
                <p>o April 2024: <a href="https://arxiv.org/abs/2312.12450"><b>Can It Edit?</b></a> presented at the LLM4Code workshop at ICSE 2024</p>
                <p>o March 2024: <b>Non-Expert Programmers in the Generative AI Future</b> accepted to CHIWORK 2024</p>
                <p>o February 2024: I visited Swarthmore to give a colloquium in the Linguistics department</p>
                <p>o February 2024: <b>Parenthesized Modifiers in English and Korean: What They (May) Mean</b> accepted to ELM 3</p>
                <p>o November 2023: <a href="https://arxiv.org/abs/2305.06161"><b>StarCoder</b></a> accepted to <i>Transactions on Machine Learning Research</i></p>
                <p>o August 2023: Received an NSF Award for research on Code LLMs for programming in the sciences, with Molly Q Feldman, Arjun Guha, and Erin G. Teich</p>
                <p>o November 2023: Three papers by EASEL lab alums presented at TADA 2023</p>
                <p>o September 2023: <b>Protagonist-Mediated Perspective</b> presented at Sinn und Bedeutung 28.</p>
                <p>o March 2024: <b>What Parenthesized Modifiers (May) Mean</b> accepted to HSP 2024</p>
                <p>o January 2024: <b>How Beginning Programmers and Code LLMs (Mis)read Each Other</b> accepted to CHI 2024</p>
                <p>o January 2024: <a href="https://arxiv.org/abs/2312.12450"><b>Can It Edit?</b></a> accepted to LLM4Code workshop at ICSE 2024</p>
                <p>o January 2024: <a href="https://arxiv.org/abs/2306.04556"><b>StudentEval</b></a> accepted to LLM4Code workshop at ICSE 2024</p>
                <p>o September 2023: <b>Cross-linguistic differences in processing parentheticals between English and Korean</b> presented at Comparative Punctuation</p><p>o July 2023: I presented a poster on <b>What (Some) Parentheses Mean</b> at UMass Linguistic's 50th anniversary celebration</p>
                <p>o August 2023: Our <a href="https://www.khoury.northeastern.edu/~arjunguha/main/papers/2023-multipl-t.html"><b>MultiPL-T paper</b></a> shows how to achieve SOTA text-to-code in 3 low-resource programming languages</p>
                <p>o July 2023: I gave a <a href="https://indico.bnl.gov/event/20122/">talk</a> as part of Brookhaven National Lab's AI/ML Seminar Series</p>
                <p>o June 2023: <b>Do All Minority Languages Look the Same to GPT-3?</b> presented at SCiL 2023</p>
                <p>o June 2023: <b>Solving and Generating NPR Sunday Puzzles with Large Language Models</b> presented at ICCC 2023.</p>
                <p>o June 2023: <b>StudentEval: a Benchmark of Student-Written Prompts for Large Language Models of Code</b> draft available on Arxiv.</p>
                <p>o May 2023: BigCode project released <b><a href="https://huggingface.co/bigcode/starcoder">StarCoder</a>: May the Source Be With You!</b></p>
                <p>o April 2023: <a href="https://arxiv.org/abs/2208.08227">MultiPL-E</a> accepted to <i>IEEE Transactions on Software Engineering</i></p>
                <p>o March 2023: <b>SantaCoder: Donâ€™t Reach For the Stars!</b> wins Best Paper Award at DL4C 2023.</p>
                <p>o December 2022: <b>Grammatical Perspective-Taking in Comprehension and Production</b> accepted to <i>Open Mind</i>.</p>
                <p>o May 2023: EASEL lab member Michelle Zhao successfully defends her honors thesis. Congrats!</p>
                <p>o December 2022: I was invited to participate in the AAAI/ACM SIGAI New and Future AI Educator Program.</p>
                <p>o December 2022: EASEL lab member Skylar Kolisko successfully defends her honors thesis: <b>Names in Large Language Models</b>.</p>
                <p>o November 2022: <b>Exploring Social Biases of Large Language Models in a College Artificial Intelligence Course</b> accepted to Educational Advances in Artificial Intelligence (EAAI) 2023.</p>
                -->
            </div>
        </div>
    </div>
</div>