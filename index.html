---
layout: default
---

<!-- Page Content -->
<div class="container">

    <!-- Portfolio Item Row -->
    <div class="row">
        <div class="row">
            <div class="col-md-7">
                <h3>Welcome</h3>
            </div>
        </div>
        <div class="row">
            <div class="col-md-8">
                <p>I am an assistant professor of Computer Science at Wellesley College.</p>
                <h3>Research</h3>
                <p>My research focuses on the intersection of language, cognition, and computation.</p>

                <p>Within computer science, much of my work focuses on evaluating large language models for natural language and code generation. What are the abilities and limitations of LLMs? Can LLMs help non-expert programmers? I study these questions from a variety of angles, including model development, benchmarking and evaluation, and human-computer interaction studies.</p>

                <p>Within linguistics, I study how context-sensitive meaning is encoded in natural language. I build computational models to understand how conversation participants use knowledge about each other's mental states, and use psycholinguistic methods to understand how people select context-sensitive expressions.</p>

                 <!--<p>My dissertation, <b><a href="https://ling.auf.net/lingbuzz/005454?_s=6KVdJSTSZvacd4I_&_k=cqAtx-8HmlYak3QH">Shifting the Perspectival Landscape</a></b>, is now on <a href="https://ling.auf.net/lingbuzz/005454?_s=6KVdJSTSZvacd4I_&_k=cqAtx-8HmlYak3QH">LingBuzz</a>.</p>-->
            </div>
            <div class="col-md-1">
            </div>
            <div class="col-md-3">
                <a href="#">
                    <img class="img-responsive thumbnail" src="img/ta_small.jpg">
                </a>
                <div style="display: grid; justify-content:center">carolyn.anderson AT wellesley.edu</div>
                <div style="display: grid; justify-content:center"><h6></h6></div>
                <!--<div style="display: grid; justify-content:center">
                    <h3 class="interests">Interests</h3>
                    <h5 class="interests">o Computational Modeling</h5>
                    <h5 class="interests">o Semantics and Pragmatics</h5>
                    <h5 class="interests">o Machine Learning</h5>
                    <h5 class="interests">o Psycholinguistics</h5>
                </div>-->
            </div>
        </div>
        <div class="row">
            <div class="col-md-10">
                <h3>News</h3>
                <p>o I'm on junior research leave F24-S25</p>
                <p>o May 2024: <a href="https://arxiv.org/abs/2306.04556"><b>StudentEval</b></a> accepted to ACL Findings</p>
                <p>o May 2024: <b>What Parenthesized Modifiers (May) Mean</b> presented at HSP 2024</p>
                <p>o May 2024: <b>How Beginning Programmers and Code LLMs (Mis)read Each Other</b> presented at CHI 2024</p>
                <p>o May 2024: EASEL lab member Anders Freeman successfully defends their honors thesis. Congrats!</p>
                <p>o April 2024: EASEL lab member Sydney Nguyen wins Best Presentation award for <a href="https://arxiv.org/abs/2306.04556"><b>StudentEval</b></a> at the LLM4Code workshop at ICSE 2024</p>
                <p>o April 2024: <a href="https://arxiv.org/abs/2312.12450"><b>Can It Edit?</b></a> presented at the LLM4Code workshop at ICSE 2024</p>
                <p>o March 2024: <b>Non-Expert Programmers in the Generative AI Future</b> accepted to CHIWORK 2024</p>
                <p>o February 2024: <b><a href="https://arxiv.org/abs/2402.19173">StarCoder 2</a></b> released</p>
                <p>o February 2024: I visited Swarthmore to give a colloquium in the Linguistics department</p>
                <p>o February 2024: <b>Parenthesized Modifiers in English and Korean: What They (May) Mean</b> accepted to ELM 3</p>
                <!-- 
                <p>o November 2023: <a href="https://arxiv.org/abs/2305.06161"><b>StarCoder</b></a> accepted to <i>Transactions on Machine Learning Research</i></p>
                <p>o August 2023: Received an NSF Award for research on Code LLMs for programming in the sciences, with Molly Q Feldman, Arjun Guha, and Erin G. Teich</p>
                <p>o November 2023: Three papers by EASEL lab alums presented at TADA 2023</p>
                <p>o September 2023: <b>Protagonist-Mediated Perspective</b> presented at Sinn und Bedeutung 28.</p>
                <p>o March 2024: <b>What Parenthesized Modifiers (May) Mean</b> accepted to HSP 2024</p>
                <p>o January 2024: <b>How Beginning Programmers and Code LLMs (Mis)read Each Other</b> accepted to CHI 2024</p>
                <p>o January 2024: <a href="https://arxiv.org/abs/2312.12450"><b>Can It Edit?</b></a> accepted to LLM4Code workshop at ICSE 2024</p>
                <p>o January 2024: <a href="https://arxiv.org/abs/2306.04556"><b>StudentEval</b></a> accepted to LLM4Code workshop at ICSE 2024</p>
                <p>o September 2023: <b>Cross-linguistic differences in processing parentheticals between English and Korean</b> presented at Comparative Punctuation</p><p>o July 2023: I presented a poster on <b>What (Some) Parentheses Mean</b> at UMass Linguistic's 50th anniversary celebration</p>
                <p>o August 2023: Our <a href="https://www.khoury.northeastern.edu/~arjunguha/main/papers/2023-multipl-t.html"><b>MultiPL-T paper</b></a> shows how to achieve SOTA text-to-code in 3 low-resource programming languages</p>
                <p>o July 2023: I gave a <a href="https://indico.bnl.gov/event/20122/">talk</a> as part of Brookhaven National Lab's AI/ML Seminar Series</p>
                <p>o June 2023: <b>Do All Minority Languages Look the Same to GPT-3?</b> presented at SCiL 2023</p>
                <p>o June 2023: <b>Solving and Generating NPR Sunday Puzzles with Large Language Models</b> presented at ICCC 2023.</p>
                <p>o June 2023: <b>StudentEval: a Benchmark of Student-Written Prompts for Large Language Models of Code</b> draft available on Arxiv.</p>
                <p>o May 2023: BigCode project released <b><a href="https://huggingface.co/bigcode/starcoder">StarCoder</a>: May the Source Be With You!</b></p>
                <p>o April 2023: <a href="https://arxiv.org/abs/2208.08227">MultiPL-E</a> accepted to <i>IEEE Transactions on Software Engineering</i></p>
                <p>o March 2023: <b>SantaCoder: Donâ€™t Reach For the Stars!</b> wins Best Paper Award at DL4C 2023.</p>
                <p>o December 2022: <b>Grammatical Perspective-Taking in Comprehension and Production</b> accepted to <i>Open Mind</i>.</p>
                <p>o May 2023: EASEL lab member Michelle Zhao successfully defends her honors thesis. Congrats!</p>
                <p>o December 2022: I was invited to participate in the AAAI/ACM SIGAI New and Future AI Educator Program.</p>
                <p>o December 2022: EASEL lab member Skylar Kolisko successfully defends her honors thesis: <b>Names in Large Language Models</b>.</p>
                <p>o November 2022: <b>Exploring Social Biases of Large Language Models in a College Artificial Intelligence Course</b> accepted to Educational Advances in Artificial Intelligence (EAAI) 2023.</p>
                -->
            </div>
        </div>
    </div>
</div>